{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "РАСПОЗНАВАНИЕ ИЗОБРАЖЕНИЙ С ПОМОЩЬЮ CNN"
      ],
      "metadata": {
        "id": "z8j7uXHcl0-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vqDsle3nrtMG",
        "outputId": "b90f4949-b751-40dd-8788-4dd842c27459"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.25.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.0)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.1)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.64.1)\n",
            "Requirement already satisfied: tensorboard<2.16,>=2.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.2)\n",
            "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: keras<2.16,>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.15.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2024.6.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.5)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.6.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from pathlib import Path\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ],
      "metadata": {
        "id": "M2gOerlLmOxw"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "После импорта библиотек будет произведена загрузка набора данных для обучения и тестирования\n",
        "x_tr=x train\n",
        "\n",
        "x_te=x test\n",
        "\n",
        "y_tr=y train\n",
        "\n",
        "y_te=y test"
      ],
      "metadata": {
        "id": "CLSwcOXMnL7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_tr,y_tr),(x_te,y_te)=cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9h2u5rM8nR0X",
        "outputId": "99022843-cefa-4cca-c6e1-bfa25ed2abdd"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 3s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Нормализация набора данных\n",
        "\n",
        "Тип данных изменяется на 32-битный тип float, а затем нормализуется."
      ],
      "metadata": {
        "id": "UcoxyeXKnfTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_tr=x_tr.astype('float32')\n",
        "x_te=x_te.astype('float32')\n",
        "x_tr/=255.0\n",
        "x_te/=255.0"
      ],
      "metadata": {
        "id": "DWh6e1l2nglm"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "после нормализации преобразовываем векторы классов в бинарные матрицы классов"
      ],
      "metadata": {
        "id": "WXovXwYyn0Bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_tr=to_categorical(y_tr,10)\n",
        "y_te=to_categorical(y_te,10)"
      ],
      "metadata": {
        "id": "rpgvIANtoS2f"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "keras Conv2D - это слой двумерной свертки. Этот слой создает ядро свертки, которое наматывается на вход слоев, что позволяет получить тензор выходов.\n",
        "\n",
        "Kernel: В обработке изображений ядро - это сверточная матрица или маска, которая может использоваться для размытия, повышения резкости, рельефности, определения краев и т. д. путем свертки ядра и изображения."
      ],
      "metadata": {
        "id": "sqcs_c9SoWxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(32,(3,3),padding='same',input_shape=(32,32,3),activation='relu'))\n",
        "model.add(Conv2D(32,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64,(3,3),padding='same',activation='relu'))\n",
        "model.add(Conv2D(32,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10,activation='softmax'))"
      ],
      "metadata": {
        "id": "efg0Zx_Boo83"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Компиляция модели осуществляется с помощью (model.compile)."
      ],
      "metadata": {
        "id": "jyhB47VHoxN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6aTyGFOo3Yv",
        "outputId": "dedcb6bc-ffb9-41c6-faee-c6a66166405e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 15, 15, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 15, 15, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 13, 13, 32)        18464     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 32)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 6, 6, 32)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1152)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               590336    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 642570 (2.45 MB)\n",
            "Trainable params: 642570 (2.45 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подгонка данных для модели.Здесь данные подгоняются в соответствии с размером партии. Передаются обучающие данные x,y. Затем передаются проверенные данные Test of x,y."
      ],
      "metadata": {
        "id": "YsOQZ4v_o8VX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_tr,y_tr,batch_size=32,epochs=8,validation_data=(x_te,y_te),shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNhkFne0pJ02",
        "outputId": "9c63bc1e-c830-4908-a528-7458411c7e36"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1563/1563 [==============================] - 189s 120ms/step - loss: 1.5432 - accuracy: 0.4326 - val_loss: 1.1763 - val_accuracy: 0.5800\n",
            "Epoch 2/8\n",
            "1563/1563 [==============================] - 183s 117ms/step - loss: 1.1647 - accuracy: 0.5824 - val_loss: 1.0070 - val_accuracy: 0.6460\n",
            "Epoch 3/8\n",
            "1563/1563 [==============================] - 179s 115ms/step - loss: 1.0103 - accuracy: 0.6421 - val_loss: 0.8679 - val_accuracy: 0.6930\n",
            "Epoch 4/8\n",
            "1563/1563 [==============================] - 181s 116ms/step - loss: 0.9193 - accuracy: 0.6748 - val_loss: 0.7934 - val_accuracy: 0.7257\n",
            "Epoch 5/8\n",
            "1563/1563 [==============================] - 179s 114ms/step - loss: 0.8534 - accuracy: 0.6997 - val_loss: 0.7798 - val_accuracy: 0.7305\n",
            "Epoch 6/8\n",
            "1563/1563 [==============================] - 181s 116ms/step - loss: 0.8065 - accuracy: 0.7141 - val_loss: 0.7498 - val_accuracy: 0.7422\n",
            "Epoch 7/8\n",
            "1563/1563 [==============================] - 180s 115ms/step - loss: 0.7752 - accuracy: 0.7309 - val_loss: 0.7458 - val_accuracy: 0.7482\n",
            "Epoch 8/8\n",
            "1563/1563 [==============================] - 180s 115ms/step - loss: 0.7387 - accuracy: 0.7387 - val_loss: 0.7040 - val_accuracy: 0.7589\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7f828e01e290>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сохранение архитектуры нейронной сети. Здесь данные преобразуются в json, который затем записывается в model_structure."
      ],
      "metadata": {
        "id": "wWD45igtpXCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_structure=model.to_json()\n",
        "f=Path(\"model_structure.json\")\n",
        "f.write_text(model_structure)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tcc3OOyvpYDH",
        "outputId": "2697d659-2c4a-4088-8b2e-776c57f5214a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6342"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Формат сохранения - json. Мы также сохраним обученные нейронные веса для предсказаний."
      ],
      "metadata": {
        "id": "0NMXFajZpbz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(\"model_weight.h5\")"
      ],
      "metadata": {
        "id": "uLb7l-twpjP_"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Здесь начинается основная часть работы. Предсказания будут делаться по изображениям на основе меток на них."
      ],
      "metadata": {
        "id": "kJO9ZY9ppoCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import model_from_json\n",
        "from pathlib import Path\n",
        "from keras.preprocessing import image\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "aNoR_j7rpvC-"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "class_labels определены, соответственно, разделение производится на основе меток класса."
      ],
      "metadata": {
        "id": "iGldvvxyp6Ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels=[\"Planes\",\"Car\",\"Bird\",\"Cat\",\"Deer\",\"Dog\",\"Frog\",\n",
        "              \"Horse\",\"Boat\",\"Truck\"]"
      ],
      "metadata": {
        "id": "4B7qo0H0p68W"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка json-файла, содержащего структуру модели, которую мы загрузили после завершения подгонки модели.\n",
        "\n",
        "write_text для записи данных в json-файл.\n",
        "\n",
        "read_text для чтения данных из json-файла."
      ],
      "metadata": {
        "id": "dU1-q2EPqHan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f=Path(\"model_structure.json\")\n",
        "model_Structure=f.read_text()"
      ],
      "metadata": {
        "id": "KUus-KNhqIP2"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка изображения выполняется для тестирования. (load_img используется для загрузки изображения) размер используется (32,32), так как при создании модели задан размер (32,32)"
      ],
      "metadata": {
        "id": "jeWaXdQyqTBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "# Загрузка и отображение изображения для тестирования\n",
        "img = load_img(\"/content/drive/MyDrive/Colab_Notebooks/bird.jpg\", target_size=(32, 32))\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "5tlsvpbGqUEG",
        "outputId": "47c67791-f32e-4cfb-d7d5-a4cf354112d8"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAbiklEQVR4nO3caXQdhHnm8ffqSlfb1Wpttmx5wza2AYM3AmEt65SEQ5PScackYclMk5mBtqFtymRps3DahtIsTcNJ2pDQJiVQEoaYhGAIoTiExWb1blneZVmyLF3rSrr3SneZD3POe2Y++XnP6ZyZzvn/Pj/n8bXu8uh+0JuoVCoVAwDAzKr+bz8AAMD/OxgFAIBjFAAAjlEAADhGAQDgGAUAgGMUAACOUQAAuGo1+P2/+uNQ8dA7b8jZyfEzoe7apJ5tTbeEuicmJ+VsslIOddfUp/VsTW2oOz+ZDeUbG5rk7Ej2dKg7l9d/Lonq2N9Olqv032OmCrHfeU4XY4+lMKvnB04eD3W3NbTL2TULYq/xc3u75eyJU6Oh7nRrm5w9dvJkqLu+pi6Ub1pwoZy96/djn2/JpP4hVJ4phLqzxw/J2a/9+R+Guv/mhTfPmuGbAgDAMQoAAMcoAAAcowAAcIwCAMAxCgAAxygAAByjAABwjAIAwDEKAADHKAAAXKJSqUgHXL72hf8QKs4f0++aNM0GjhmZWX5iWs6WZxOhbkvod3vu+co3Q9U/eu51OXtmSv8/mpkt6u4M5Z/53lf1cD4X6p6enZKzmZnZUHfHog45296r3+ExM2tdqnebmaXS+v2o5oY5oe7Bt/bI2fKO4VB3dXXg/dYQuzd0/LR+O2y2Ip9eMzOz6Xw+lD80qN+bapoTe/+ku/X7UfOXLwt1b9ywVs4m6ouh7k03f/ysGb4pAAAcowAAcIwCAMAxCgAAxygAAByjAABwjAIAwDEKAADHKAAAHKMAAHDy35lXpWKnDpo66+Xs0LtHQt1z5yyUswePxbpPjY/J2S/ec1eou1jR/yT9nUzs/EPf+ReH8i8M6Gc0Xv2XX4W6v/i5z8vZz919d6j7VDYjZ8vB33lyudhrvLZWf41v2/ZaqHvJogvk7FTnoVB3y3z9cT/8yKOh7oH9+nmbrnTs9EexNBPKZwq1cvbYoZFQ96rAVYy1V10S6p6/SD+hMVuOfU4o+KYAAHCMAgDAMQoAAMcoAAAcowAAcIwCAMAxCgAAxygAAByjAABwjAIAwDEKAACXqFQqFSX41fsvDxVPHpqUs3WlxlB3ZkS/21NJSf89N9Wl3z5qP6cU6q50luVsqkU+S2VmZlV1ereZ2cl35snZ2T3LQ90bLr9Wzg6ePBXqfuTvvytnzz//olB3Y1M6lB/of13OnhzT716Zma1Zoj8/uUrscV935UY5W5kZCnXvOXFMzu5793CoO5mI/Q47kcnI2WIl9l4uzRTk7NoLYq/Df/9fPihn2/vmh7rfs+rs702+KQAAHKMAAHCMAgDAMQoAAMcoAAAcowAAcIwCAMAxCgAAxygAAByjAABw8pmLz9xzfqg4P5rXs+lMqHvBpfqf9betWBjqLpdycnY6r5/yMDPLFfQTGvUNNaHu4dOxcxGtTT1y9qPrtoa6x4b0MyTDwyOh7pbmNjl74OChUPerr2wL5RvTDXJ2//7doe6Fi/QzFyf694a6V6+5UM621CdD3b0d+vNTTsZO0Lx8UD+hYWb27JM/lrMzU/r73sysq00/zVNTip2gWdm3VM5+6J6PhbrXX/e+s2b4pgAAcIwCAMAxCgAAxygAAByjAABwjAIAwDEKAADHKAAAHKMAAHCMAgDAMQoAACffPvq7b98WKk4vrpWz+ZR+J8nMLFmr50fHjoS6E4mCnG1siW3q8Ih+u2Uyq98PMjOrTup3eMzMksmUnL2h93uh7q62ZXK2kI/dhRkePilnM5lsqDubjeXr6urk7BOPPhTqbq2vl7MLF/aFuk8M6LeSVq84J9TdkNZvAh05EntvXvfxO0L5UqFazo4O6nfJzMwe+uoDcnZRi/4zMTPrDNw962rrDnX/wbe+e9YM3xQAAI5RAAA4RgEA4BgFAIBjFAAAjlEAADhGAQDgGAUAgGMUAACOUQAAOPnvwOvm6n/Sb2Y2cOKQnK3UTIW6SxX9HMF0fjzUnZ2akLONjbE/Xy+V9D+7n5rUz1CYmRVnY+ciSmX959K7YWGouyahn9wo5CdD3Q3ptJxNWPBnWJwJ5Qf2H5CzV1x+Q6h795tb5eyHfntTqPuT9/6+nH3sx5tD3Z+45w/k7M6du0Pdr21+PpS//raPyNnadOxMzOf++kE5u+dd/ayImdmWf/q2nJ0thaolfFMAADhGAQDgGAUAgGMUAACOUQAAOEYBAOAYBQCAYxQAAI5RAAA4RgEA4BgFAICTj/HsGno1VJw5fVrPTo6GumsS9XJ2IhO7CdTZ0i1nd4yMhLrr6/VbSbXVLaHuZDIZyp/OFuTsvZ++PdT94Od+IGfL5djzMzqqv1b27tkf6t6w4eJQ/syZM3I2lSyGuhct7JGz9/23Pwx1v/fqS+Tsjrf3hLoTph/jGR0Pvu8PHw7lp7IZOTtTiR0RStbov0+vWr8q1L1o2Z/K2ef++YlQt4JvCgAAxygAAByjAABwjAIAwDEKAADHKAAAHKMAAHCMAgDAMQoAAMcoAACcfOais0M/0WBmNp0/KWd70vppCTOz0oyezU3p5zbMzCqBcwTNLfq5DTOzM2PjcnZOz4JQd76YDeVr6xJy9q4P3BHrTtXJ2YYG+SVoZmbd3fprZcH8haHuREL/mZiZ7e8fkLN33nlnqPu1in7+4xM3bQp173pli5xtrNefSzOzF176pZxtbusKddfVp0L5xpqKnE2UYr8flxP68zNTCHxgmVljc4OcvfmO20LdCr4pAAAcowAAcIwCAMAxCgAAxygAAByjAABwjAIAwDEKAADHKAAAHKMAAHCMAgDAJSqVinQg5JHnPxQqLqYPytmjR4+EugcODMrZpnRTqDuZrJWz2YmpUHdmLCdnq4J3eOa094TyM8WCnP2T970S6p6c1m+9vL59e6h7/fr1crZQ0P+PZmZ9fX2h/K6d++Ts4sWLQ91ViZKcffGFn4e6L914kZzNZ4dC3ScGdsvZpnRLqPsnm58K5RM1+q2k2z/72VB3Lq+/96tSNaHuQi4vZxsbYzfpLlqx9qwZvikAAByjAABwjAIAwDEKAADHKAAAHKMAAHCMAgDAMQoAAMcoAAAcowAAcIwCAMBVq8Gp2TOh4rHBjJydLcZuCPX2NcjZhgb9lpGZ2cTEpJytbYjdJ1q6Yp6cLRVj3ZM56YSVu+/Xt8rZvTtHQ91jGf1neP3114W6p6b010pvb2+ou7+/P5RfvvwcOXvseOy+1+jIaTl77qrVoe4nNm+Ws4vmdYS6a0v6zaZrLj77HZ7/rTsZ+x126wvPy9mZQuwzqKpav6tUFfzdu7EuLWcL07H7Xgq+KQAAHKMAAHCMAgDAMQoAAMcoAAAcowAAcIwCAMAxCgAAxygAAByjAABw8pmLUnI8Vlw3K2e7WrpC3bn8hJwtl0PVtnjRfDk7NpoNdSeS+imKqtiVC/uz658O5V/fulPOTs/EToXMnav/DE8Oxc4/RJ7P/v17Q92pmrpQ/vDMjJwdPHYs1D0xrZ9dyOUzoe78Gf1kTc/5+ikPM7NHv/eEnD12eF+ouz2tn38wM5sw/U104OcvhbqX33CNnE1VyR+zZmaWD7yuqqtj3Qq+KQAAHKMAAHCMAgDAMQoAAMcoAAAcowAAcIwCAMAxCgAAxygAAByjAABwjAIAwMmHMyrZllDx/MX6nZ/hUyOh7sZG/bGkg/dSSkX9uE5tfSnUPTE2KmcXdl8U6r77d343lP+t375HznbM6w51Vyf1n2FzYyrUPTWVk7OtTbHumlTsjkz/Qf12T6Wivx/MzKrK+u2jzubWUHdp+oSc/dnTsftEkadz809/Eure9Ju3hvLHjxyVs8VS7Pl5+PHH5OwXv/XtUHdVRf9dfbYc+wyS/v1/9UYAwL9ZjAIAwDEKAADHKAAAHKMAAHCMAgDAMQoAAMcoAAAcowAAcIwCAMDJf9f/7N8cDBXf9JkOOTt/3txQdzarnwDIT+VD3clkrZxNNzSGunt7F8jZukNLQ92XbWwO5SeyR+Ts7PFCqDuV0m8ddHbMC3XnJsbkbKlQDHWP5/UTGmZmPR36uZVksib2WIb1xz58cjDUfcl71snZd3e+E+puW7ZcztZ16p8RZmYvbXs7lD96/LicLSWToe6Gav2US0tjQ6h7NvCyTRRi700F3xQAAI5RAAA4RgEA4BgFAIBjFAAAjlEAADhGAQDgGAUAgGMUAACOUQAAOEYBAOASlUqlogRv/cBFoeK6tH6L5999uC3UPdt8Ws4W84lQd1VKv1OSbugOdScCG/z1O58LdX/01ttC+ZFMRs4uX3leqNtq9J9hfV3sZpMl9JszxWLs9lFTy5xQfiyr30qqb0iHurMTE3L2lZd/Eep+z7o1enhWf6+ZmQ0PD8nZrp6+UPdTTz4VyuenZ+VspRS7IbRx7Vo5+9ZB/WdiZnbnH98nZ7OF2L2uW66+9qwZvikAAByjAABwjAIAwDEKAADHKAAAHKMAAHCMAgDAMQoAAMcoAAAcowAAcNVqMFXbEirubtNPV7zxZFOo++O/d6+cPZR9IdSdTrXL2epkY6i7OlEnZ+++e3moe+T4iVC+u6tVzmYCJzHMzBatXCJn9+87EOpevmyZnK0p6ycxzMwyE1Oh/PSM/jtVY3Nt8LGMy9m+BYtC3YeO6q+VlOnnNszMmur0/+fu7VtD3eOnjobyoxP66YqWwFkeM7PHf/i4nF2xal2o+8zEpJydCb7GFXxTAAA4RgEA4BgFAIBjFAAAjlEAADhGAQDgGAUAgGMUAACOUQAAOEYBAOAYBQCAk28f5U7lQsWjtfqdn/GjR0Ldf/HA1+Rs/9Y3Qt1bHvuhnE2m06Huo7v2y9mLr/mdUHdDrfxUmpnZW8/+QM6eHMmEuvfvekfOLltxYah7ZnZWzjY063eszMysFLt9dKR/t5zt7Z0b6m6b0y1na6pjd5Uqs/o9o+72vlD3W9tfkbO5wkyou7uzI5RPt6fkbE1S/7wyM5s/V38+B46eDHVPZfXbRxMFPavimwIAwDEKAADHKAAAHKMAAHCMAgDAMQoAAMcoAAAcowAAcIwCAMAxCgAAxygAAJx8MOfQroOh4ssXXCZn285bGeo+uGOfnE121oS6P/Wl++Xsqjk9oe50Qb9PlHv8uVD3R7755VA+mWqTs0f2/CrUve6qG+Xs81ueCnWff9EFcvZ0ZjTUPXf+4lC+UNDvMO3v3xXqnpzUb9pMB7JmZq0t+p2fzFjsHlQxp99Vqg/e60paKZQvF07L2exM7PfjA4P6a6u3K/Y5kc/pj7u1rSHUreCbAgDAMQoAAMcoAAAcowAAcIwCAMAxCgAAxygAAByjAABwjAIAwDEKAAAn/535ivnzQsU3XXuTnP3BM0+EumdqEvrjuOp9oe6nn3lRzp6qKoa6z0zpJwPOOaGfCzAz+8sbrwzl/+sT35Oz2bGToe7Bgf1ydk5rfah7x1tvytnehYtC3SODA6H8mnOXydl0W3eo+8DAITnbOq8r1J2fPiVnd+/aE+o+NaSfaOjraQ51D50cCeVb001y9uI154S6X3nnsJxta8mHupva9d/V6ztqQ90KvikAAByjAABwjAIAwDEKAADHKAAAHKMAAHCMAgDAMQoAAMcoAAAcowAAcIwCAMDJt48+9Z37Q8Vf/8xX5OyvXXZFqPuX+7fJ2edffjHUvXyFfqNm357YrZzFK/RbOcfaY3eVduXPhPJzP3a7nF156wdD3Qf69Xs5kzP6HSszs1RtUs5Ojes3fszMWlsaQ/ndb78kZ9dv2BDqTs7o96ayZ0qh7qZG/f85k4u9rvrmzpGzqcANMzOzdDodyre36bePJjKx/+fV79Wfz6PHDoe6q9KB5zMZe9zSv/+v3ggA+DeLUQAAOEYBAOAYBQCAYxQAAI5RAAA4RgEA4BgFAIBjFAAAjlEAADj5zMUb294IFWeH9D/Tv/Y3Y2cUBv9W7y6t0M8imJnNZCblbE1DJdS9pHuBnB2YyoW6r7r+ylD+uXdel7OTP/pZqHssoT/2uUv00x9mZq3z58vZAwf1cxtmZoWp0VB+5Xkr5OzzP98S6u7o6JCzmfGJUHdjb4+cLWbGQ90TuSk5m6yKnedob6wJ5U+N6s9nck5LqPvFF96Ws1fdeGmo2xL6iZu2tq5Yt4BvCgAAxygAAByjAABwjAIAwDEKAADHKAAAHKMAAHCMAgDAMQoAAMcoAAAcowAAcPLto8XnLgoVf+xrn5SzB4Z3hro33qTfEtn55W+Euucs6ZWzrYE7SWZmiy/Q7/Zs3/5mqHvHq7F8cTwrZ38cuGdjZnZOT7ecPb19e6j7xiWL5Gx9Vex3np7A4zYz2/eu/rrtbGkOdbc1t8rZxvr6UPfYlP7ct3a3h7qzQyNytrGtKdSdbojlR0+dkbO9nbHnfvmKpXJ2/a3vCXUnTX8+01X6jSwV3xQAAI5RAAA4RgEA4BgFAIBjFAAAjlEAADhGAQDgGAUAgGMUAACOUQAAOPnMxXThQKj4v//0Z3K2c25PqHs6Oy1nV16mn5YwMzu8Uz9dsfbydaHuf/z2I3K2pjYd6h4aHAvlk9VlOdvXFjsB0NjRJmeLc2OnCwqFUTnbUNHPOZiZ9b99OJSfzOmvlQUL9PMpZmYLu1bK2YGB/lB3W4P+2qoKnpbY8uYOOTu3MhvqjpytMDPrm6//zB/84Uuh7gcf+4ScnS7E3ptNLUk5m8lkQt0KvikAAByjAABwjAIAwDEKAADHKAAAHKMAAHCMAgDAMQoAAMcoAAAcowAAcIwCAMDJt49+ufe1UPEFG/XbLYeOHAx1N3Xot1saGhOh7pGMfuNp8MWToe7lq5boj+PYSKh7R3/sNlVzVYOczXXmQt1WU5GjDXWx2zrf3/OynP3C1/801D04qN/tMTOrP6G/tva+GbutM3j4XTl7tD92++jCNZfI2e3b3gx1b1in3wMbOBx7zTbW18XyZf11+4vHHwp1P7bnaTlbCN7gOjGi3/fK5/T3mpnZr619/1kzfFMAADhGAQDgGAUAgGMUAACOUQAAOEYBAOAYBQCAYxQAAI5RAAA4RgEA4OQzF8WZUqh4bGxSzq5atibUPa+7Rw+Xk6HuS++/Ss4++dAroe5iQv+T9Ktu3BDq7uh5K5Tf+vw2OZvOzYa6h4aG5ezSFW2h7vbmFjn7yJceDnWfnBoP5T/555+Vs9f2LQt1P/zlz8vZqdGhUPfh2p1ydtOd94W6v/PgvXK2rj4V6h7PnArlV66+WO8+sjfUve+QfhIlVd8a6m7M6r+rzxRiZy4UfFMAADhGAQDgGAUAgGMUAACOUQAAOEYBAOAYBQCAYxQAAI5RAAA4RgEA4BgFAICTbx+tX355qLijc56crU81h7qf/cU/ytn33fDhUHeiJP9I7O4/inV/5xs/kLO9KxaEup97/ulQ/tzV8+Xs8cOxm0BTwzk5O3DgmVD3+o3r5OyRw8dC3eetXhnKt83qr9vU0q5Q92336jeHnvn+o6HuXdv1u1fX/Uf91pSZ2bHxKTnbNVsOdU/ETnDZNze/IGfrt+r3oMzM/uTv9Z95VfBx19XV6dlUfaxcwDcFAIBjFAAAjlEAADhGAQDgGAUAgGMUAACOUQAAOEYBAOAYBQCAYxQAAI5RAAA4+dDPjqOTseLBt+VsuSZ2HCTVslDO7urfF+q+7spr5OzYaD7UfckV58vZr37+wVD3xvdfEsoXM/rdma6OU6Hundv3yNm+tH6DycysUJWQs4lkKtQ9sPdgKP/AFz4vZ1M5/aaWmVnn6ovk7J1f/NtQd+5Y4P852xjqHszp+YOjJ0Pdixb2hfLJqhk5O1WIvZeXNnXL2aqW2M+wWNTfm+Xg/SgF3xQAAI5RAAA4RgEA4BgFAIBjFAAAjlEAADhGAQDgGAUAgGMUAACOUQAAuESlUqkowR+/+FiouKOlXs62NMX+DLxc0rOptP6n7mZm//DUn8nZO97/rVD3lq3fkLPPbtkc6r6o9+pQvn/8uJwdeu1IqPu5l3fJ2SvPWx3qXr5az48MDoa6O1fp51PMzOqy+mmE6qT+fjAza21pl7Pzk02h7o4aPbv0vfrZFzOzseSEnH3k+98NdR86fjSUt2SdHO0KfF6ZmV2x9go5e8en9XMoZmalSuDMRTHwYWhm7XOaz5rhmwIAwDEKAADHKAAAHKMAAHCMAgDAMQoAAMcoAAAcowAAcIwCAMAxCgAAxygAAFy1GlzY2xoqLuQycrZcCW5TInC8pXT2Wx//q4988D45+/BT/ynU/Xu/8U9ytslaQ92Hhg6G8rWHpZNX//OxdDeEuj/6WzfJ2SfffivUffs1N8jZUlG/IWNmdnrvUCg/U1eUs+Vs7AZXXW1Czh5Pt4W6P/2JL8nZHa//MtT9w20/kbPlKv01aGbW1tIayp+e0G9TdbZ1h7oPHt8vZ0ul2H2iRFL/PKxOBT4LRXxTAAA4RgEA4BgFAIBjFAAAjlEAADhGAQDgGAUAgGMUAACOUQAAOEYBAODkMxenC78KFecL+p921xTqQt3Fov6n3e2tc0Pd6dl2OdtUFzuh8ZUnNsnZnz9xNNR9wZrYY+nqPVfOLujpDXUPn87I2c/857tC3Y9ueVHO1lXrZyjMzO76jZtD+YkzOTmbLeonF8zMkqkuObv2/KtD3UeH9RMNbwzuCXV/+e8elbMf3vTroe7W5pZQ/sy0flrk3YH+UPeSefrnyms/3RzqvuTmW+RsIqGfQ1HxTQEA4BgFAIBjFAAAjlEAADhGAQDgGAUAgGMUAACOUQAAOEYBAOAYBQCAYxQAAC5RqVQqSvChl84LFZdLycCjkE8wmZlZbY1+52e2EKq2toYlcjZVNSfUvXP3q3K2HLwHla6cE8ofm/oXObukeFOoe2TsuJydHddvZJmZfeGBh+RsthK7C1NdnQrlb16zTM7WNM0PdScSk3I21RR73H1NnXI2X47dj/rAB2+Rs+uu+UCo+56PfySUzwXe/Ht26vegzMzOPWeBnL2wty/U/al/+Gc5K358u6b6s79W+KYAAHCMAgDAMQoAAMcoAAAcowAAcIwCAMAxCgAAxygAAByjAABwjAIAwMlnLn60/dJQcSY3JmdHJ0dD3bW1tXJ2MpsLdadqa+RsqVgOdZfH18vZ6kRsr6ezsXME+Rn9+XnmmXdD3bdc/GE5OzYxG+ounTojZz/5F38V6q6ubYjlTT/lcstl60LdPW0dcnZ45HSou6lZ/382tbWHuhtS+nuzpb0l1D0zFXtPrL/hOjn70AP3h7oXzNV/Lrdv2hTqvu53/0jOcuYCAPB/FKMAAHCMAgDAMQoAAMcoAAAcowAAcIwCAMAxCgAAxygAAByjAABwjAIAwMm3jwAA///jmwIAwDEKAADHKAAAHKMAAHCMAgDAMQoAAMcoAAAcowAAcIwCAMD9D+oPPLyhBPIDAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "После загрузки изображения в переменную мы должны преобразовать его в массив numpy. Здесь изображение преобразуется в массив, а затем расширяется в соответствии с размерами массива согласно строке. (Для преобразования используется img_to_array)"
      ],
      "metadata": {
        "id": "7-QZYt9Qqevn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import img_to_array\n",
        "imgtest=img_to_array(img)\n",
        "list_of_image=np.expand_dims(imgtest,axis=0)"
      ],
      "metadata": {
        "id": "6wWI6INpqkC-"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "После преобразования в массив. Затем на основе массива делаются прогнозы."
      ],
      "metadata": {
        "id": "hFipy26Uqr5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res=model.predict(list_of_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8P9VoYKnqvz2",
        "outputId": "745f894d-77cb-415f-c559-c9b89fd0ee9b"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Учитывается только один результат, так как берется только одно изображение. Если есть группа изображений, то запускается цикл, или набор данных классифицируется соответствующим образом. Распечатывается массив для всех меток."
      ],
      "metadata": {
        "id": "g5VHtCZ0q7vP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sr=res[0]\n",
        "print(sr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPZu6RpOq8dG",
        "outputId": "a46936cb-c2df-46ef-c2a8-1b832a43c07f"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы получим оценку, которая представляет собой вероятность всех 10 возможных классов. Когда изображение получает наивысшую оценку вероятности, ему присваивается метка. В результате будет выведена метка изображения."
      ],
      "metadata": {
        "id": "JOOMoeJkrEa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mostlci=int(np.argmax(sr))\n",
        "clh=class_labels[mostlci]\n",
        "print(clh,mostlci)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnAokHisrI1t",
        "outputId": "4584fb44-a4f0-49da-f9ff-2b77a819a11d"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Truck 9\n"
          ]
        }
      ]
    }
  ]
}