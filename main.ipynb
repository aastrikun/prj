{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "РАСПОЗНАВАНИЕ ИЗОБРАЖЕНИЙ С ПОМОЩЬЮ CNN"
      ],
      "metadata": {
        "id": "z8j7uXHcl0-x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "from pathlib import Path\n",
        "from tensorflow.keras.utils import to_categorical\n"
      ],
      "metadata": {
        "id": "M2gOerlLmOxw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "После импорта библиотек будет произведена загрузка набора данных для обучения и тестирования\n",
        "x_tr=x train\n",
        "\n",
        "x_te=x test\n",
        "\n",
        "y_tr=y train\n",
        "\n",
        "y_te=y test"
      ],
      "metadata": {
        "id": "CLSwcOXMnL7Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_tr,y_tr),(x_te,y_te)=cifar10.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9h2u5rM8nR0X",
        "outputId": "73715c44-22c3-4988-93f8-8732c826eefa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 4s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Нормализация набора данных\n",
        "\n",
        "Тип данных изменяется на 32-битный тип float, а затем нормализуется."
      ],
      "metadata": {
        "id": "UcoxyeXKnfTI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_tr=x_tr.astype('float32')\n",
        "x_te=x_te.astype('float32')\n",
        "x_tr/=255.0\n",
        "x_te/=255.0"
      ],
      "metadata": {
        "id": "DWh6e1l2nglm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "после нормализации преобразовываем векторы классов в бинарные матрицы классов"
      ],
      "metadata": {
        "id": "WXovXwYyn0Bg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_tr=to_categorical(y_tr,10)\n",
        "y_te=to_categorical(y_te,10)"
      ],
      "metadata": {
        "id": "rpgvIANtoS2f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "keras Conv2D - это слой двумерной свертки. Этот слой создает ядро свертки, которое наматывается на вход слоев, что позволяет получить тензор выходов.\n",
        "\n",
        "Kernel: В обработке изображений ядро - это сверточная матрица или маска, которая может использоваться для размытия, повышения резкости, рельефности, определения краев и т. д. путем свертки ядра и изображения."
      ],
      "metadata": {
        "id": "sqcs_c9SoWxA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(32,(3,3),padding='same',input_shape=(32,32,3),activation='relu'))\n",
        "model.add(Conv2D(32,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(64,(3,3),padding='same',activation='relu'))\n",
        "model.add(Conv2D(32,(3,3),activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(512,activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(10,activation='softmax'))"
      ],
      "metadata": {
        "id": "efg0Zx_Boo83"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Компиляция модели осуществляется с помощью (model.compile)."
      ],
      "metadata": {
        "id": "jyhB47VHoxN3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6aTyGFOo3Yv",
        "outputId": "38bec92e-f61d-4422-c800-3dde8ebb6fb7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 30, 30, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 15, 15, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 15, 15, 32)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 15, 15, 64)        18496     \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 13, 13, 32)        18464     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 6, 6, 32)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 6, 6, 32)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 1152)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 512)               590336    \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 512)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 642570 (2.45 MB)\n",
            "Trainable params: 642570 (2.45 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Подгонка данных для модели.Здесь данные подгоняются в соответствии с размером партии. Передаются обучающие данные x,y. Затем передаются проверенные данные Test of x,y."
      ],
      "metadata": {
        "id": "YsOQZ4v_o8VX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_tr,y_tr,batch_size=32,epochs=20,validation_data=(x_te,y_te),shuffle=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LNhkFne0pJ02",
        "outputId": "c534a148-fa9b-4cee-8714-11ed141a79b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "1563/1563 [==============================] - 204s 130ms/step - loss: 1.5256 - accuracy: 0.4392 - val_loss: 1.2226 - val_accuracy: 0.5598\n",
            "Epoch 2/20\n",
            "1563/1563 [==============================] - 208s 133ms/step - loss: 1.1761 - accuracy: 0.5797 - val_loss: 1.0216 - val_accuracy: 0.6352\n",
            "Epoch 3/20\n",
            "1563/1563 [==============================] - 205s 131ms/step - loss: 1.0200 - accuracy: 0.6377 - val_loss: 0.8841 - val_accuracy: 0.6848\n",
            "Epoch 4/20\n",
            "1563/1563 [==============================] - 205s 131ms/step - loss: 0.9304 - accuracy: 0.6709 - val_loss: 0.8228 - val_accuracy: 0.7137\n",
            "Epoch 5/20\n",
            "1563/1563 [==============================] - 208s 133ms/step - loss: 0.8680 - accuracy: 0.6952 - val_loss: 0.8407 - val_accuracy: 0.7072\n",
            "Epoch 6/20\n",
            "1563/1563 [==============================] - 203s 130ms/step - loss: 0.8305 - accuracy: 0.7069 - val_loss: 0.7571 - val_accuracy: 0.7352\n",
            "Epoch 7/20\n",
            "1563/1563 [==============================] - 203s 130ms/step - loss: 0.7900 - accuracy: 0.7224 - val_loss: 0.7537 - val_accuracy: 0.7421\n",
            "Epoch 8/20\n",
            "1563/1563 [==============================] - 219s 140ms/step - loss: 0.7582 - accuracy: 0.7340 - val_loss: 0.7122 - val_accuracy: 0.7557\n",
            "Epoch 9/20\n",
            "1563/1563 [==============================] - 216s 138ms/step - loss: 0.7368 - accuracy: 0.7426 - val_loss: 0.7218 - val_accuracy: 0.7493\n",
            "Epoch 10/20\n",
            "1563/1563 [==============================] - 215s 138ms/step - loss: 0.7088 - accuracy: 0.7507 - val_loss: 0.7017 - val_accuracy: 0.7571\n",
            "Epoch 11/20\n",
            "1563/1563 [==============================] - 206s 132ms/step - loss: 0.6979 - accuracy: 0.7538 - val_loss: 0.6750 - val_accuracy: 0.7709\n",
            "Epoch 12/20\n",
            "1563/1563 [==============================] - 204s 131ms/step - loss: 0.6829 - accuracy: 0.7587 - val_loss: 0.6989 - val_accuracy: 0.7607\n",
            "Epoch 13/20\n",
            "1563/1563 [==============================] - 204s 130ms/step - loss: 0.6697 - accuracy: 0.7662 - val_loss: 0.6637 - val_accuracy: 0.7757\n",
            "Epoch 14/20\n",
            "1563/1563 [==============================] - 204s 131ms/step - loss: 0.6526 - accuracy: 0.7703 - val_loss: 0.6624 - val_accuracy: 0.7746\n",
            "Epoch 15/20\n",
            "1563/1563 [==============================] - 204s 131ms/step - loss: 0.6426 - accuracy: 0.7779 - val_loss: 0.6568 - val_accuracy: 0.7791\n",
            "Epoch 16/20\n",
            "1563/1563 [==============================] - 203s 130ms/step - loss: 0.6279 - accuracy: 0.7811 - val_loss: 0.6615 - val_accuracy: 0.7773\n",
            "Epoch 17/20\n",
            "1563/1563 [==============================] - 204s 131ms/step - loss: 0.6192 - accuracy: 0.7844 - val_loss: 0.6643 - val_accuracy: 0.7749\n",
            "Epoch 18/20\n",
            "1563/1563 [==============================] - 203s 130ms/step - loss: 0.6114 - accuracy: 0.7851 - val_loss: 0.6551 - val_accuracy: 0.7767\n",
            "Epoch 19/20\n",
            "1563/1563 [==============================] - 206s 132ms/step - loss: 0.6062 - accuracy: 0.7888 - val_loss: 0.6715 - val_accuracy: 0.7760\n",
            "Epoch 20/20\n",
            "1563/1563 [==============================] - 213s 136ms/step - loss: 0.5904 - accuracy: 0.7931 - val_loss: 0.7210 - val_accuracy: 0.7611\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7b014cc4a590>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Сохранение архитектуры нейронной сети. Здесь данные преобразуются в json, который затем записывается в model_structure."
      ],
      "metadata": {
        "id": "wWD45igtpXCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_structure=model.to_json()\n",
        "f=Path(\"model_structure.json\")\n",
        "f.write_text(model_structure)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tcc3OOyvpYDH",
        "outputId": "3360ff41-f9ae-40c6-ff20-37be01d70a3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6342"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Формат сохранения - json. Мы также сохраним обученные нейронные веса для предсказаний."
      ],
      "metadata": {
        "id": "0NMXFajZpbz3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights(\"model_weight.h5\")"
      ],
      "metadata": {
        "id": "uLb7l-twpjP_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Здесь начинается основная часть работы. Предсказания будут делаться по изображениям на основе меток на них."
      ],
      "metadata": {
        "id": "kJO9ZY9ppoCX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import model_from_json\n",
        "from pathlib import Path\n",
        "from keras.preprocessing import image\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "aNoR_j7rpvC-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "class_labels определены, соответственно, разделение производится на основе меток класса."
      ],
      "metadata": {
        "id": "iGldvvxyp6Ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_labels=[\"Planes\",\"Car\",\"Bird\",\"Cat\",\"Deer\",\"Dog\",\"Frog\",\n",
        "              \"Horse\",\"Boat\",\"Truck\"]"
      ],
      "metadata": {
        "id": "4B7qo0H0p68W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка json-файла, содержащего структуру модели, которую мы загрузили после завершения подгонки модели.\n",
        "\n",
        "write_text для записи данных в json-файл.\n",
        "\n",
        "read_text для чтения данных из json-файла."
      ],
      "metadata": {
        "id": "dU1-q2EPqHan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f=Path(\"model_structure.json\")\n",
        "model_Structure=f.read_text()"
      ],
      "metadata": {
        "id": "KUus-KNhqIP2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Загрузка изображения выполняется для тестирования. (load_img используется для загрузки изображения) размер используется (32,32), так как при создании модели задан размер (32,32)"
      ],
      "metadata": {
        "id": "jeWaXdQyqTBn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "from tensorflow.keras.utils import to_categorical, load_img, img_to_array\n",
        "import matplotlib.pyplot as plt\n",
        "drive.mount('/content/drive')\n",
        "# Загрузка и отображение изображения для тестирования\n",
        "img = load_img(\"/content/drive/MyDrive/Colab_Notebooks/horse.jpg\", target_size=(32, 32))\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "5tlsvpbGqUEG",
        "outputId": "81549b90-308f-4cef-e4d9-2dee4b3e7744"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZDklEQVR4nO3cWW8chnXF8Tv7zuEiUlwka5clWYsr2YkXtUAKJEVgNw9BURQI8iWCfJKi/RBtHwLU7hYHdWLBWtLasWNtlCMxIkXG4jrDGc6+9CHtffU9QIU2wP/3fHw9nIVH88CTGI/HYwMAwMyS/9cPAADw/welAABwlAIAwFEKAABHKQAAHKUAAHCUAgDAUQoAAJeOBs+fPyodnpmZCWcbjYZ0e21tLZw9duyYdLter4ezvd5Auj0xMRHODgba7VqtJuVTqUw4+/y5djuRiGePH1+Ubnc7/XD2oKW9r9Km/R3neDwMZ8vl+GtvZvbSSy+Fs6VSSbq9vr4ezj7/aku6nc1mw9lcriDd3trSHksymQpnE8qb1syymXw8KzwnZma12n44OxqNpNvNXudrM3xTAAA4SgEA4CgFAICjFAAAjlIAADhKAQDgKAUAgKMUAACOUgAAOEoBAOAoBQCAS4zH49DgSzKpbYNMT+fC2cOHD0u3K5VKOHvy5Enp9pMnT8LZ1dVn0u1utxvO5nLx58/MbH8/vpfy+/vx3Zl2uy3dLhTitxcXte2j1sHXb7f8j3bnQLrd72g/Z7sVfyy5XHxrysxsbm4unFU2tczMxqP4Zzn468Epm1rKzpiZ2dbWtpRX9tfUDaH1Z78LZ/vD+EaWmVlGeA6V34VmZs/3dr42wzcFAICjFAAAjlIAADhKAQDgKAUAgKMUAACOUgAAOEoBAOAoBQCAoxQAAC4dDf7Jn1yTDq+vr4ezrVZLuj0U/mx8d3dXul0ul8PZN954Q7pdLBbD2eXlL6XbqdRXUv7gID4BMRppUwfDQTzf2NemKJTZhWIh/lqamSUL8dfHzKzf34yHEynpdqfbD2cHe9pcRLkcn8VQJzQG/fhns1AsSbdn58K/rn6fn50NZ5XPg5nZXq0ZziYS2kSQku/14++TKL4pAAAcpQAAcJQCAMBRCgAARykAABylAABwlAIAwFEKAABHKQAAHKUAAHCUAgDAhcdEpqenpcMbGxvhbLfblW7XarVwtt1uS7dzuVw4e/y4tsXS6XTC2XRau53NZqV8o9EIZ8XpFmmfqNmMb8iYmRUKhXBW3e1RXnszs3oz/hymTNs+yuTiP2dXfI83W/F8uVSRbo+E98o3v/mmdPvq669J+aOLS+Hsx7fuSLc/vnEjnF199ky6vb0Z39Qaqx/OAL4pAAAcpQAAcJQCAMBRCgAARykAABylAABwlAIAwFEKAABHKQAAHKUAAHDhLYWVlRXpsDKjkMlkpNuj0Sic3dzclW4Ph/FsrbYv3d7ePghnq9W8dFuZljAza7fi0yLKtISZWblcDmd7vZ50W5n/KJVK0u1isSjlx8K/qVodbcolnY8/L/2B8KY1s2ImPucxt7Ao3Z4S5nDeeOu6dPvsuZel/EEjPqEye3heuv0Xf/lX4ezDR8vS7X/4u78PZ7d2tqXbEXxTAAA4SgEA4CgFAICjFAAAjlIAADhKAQDgKAUAgKMUAACOUgAAOEoBAOAoBQCACw/JDJVRINP2jJJJrZt6vfj2kTitY8oMk7qto2w25fPaDk8qlZLynfZWONvv97XbnU44q2xkmZklEolwttfTHvehufhmk5lZPh/fhNrb1XayhvG3ilWrVen20tJSOHv+wkXp9vHjx8PZufnD0u0bN25I+Z///KNwdn5e2z760Y9+FM6+/cfaxpOyM/ezn/1Muh3BNwUAgKMUAACOUgAAOEoBAOAoBQCAoxQAAI5SAAA4SgEA4CgFAICjFAAALjxz0WrFpwvUvDrRoCiVtNvKFEUiod2emJgMZ8+cflm6rTxuM7NmoxXONhpN6XYyGd8WERc0rN1+cRMarQPtPZ4vxGdOUpmsdHtk8TmPIy8dk25ffe31cPbc+Vek21NTU+Hs/MKidPvzX9+V8p1uN5zd3duTbq9vbISzZ86ckW5funw5nL177550O4JvCgAARykAABylAABwlAIAwFEKAABHKQAAHKUAAHCUAgDAUQoAAEcpAAAcpQAAcOHto2q1Kh0+ODgIZ9vttnR7MIhn0+mxdLvViufr9bp0u1KphLPpdPilMTOzZFLr91wuF86qu0qVykQ4m0jUpNv5fD6cHQy1135tbV3KK0+L8nybaT/nqZPats6rV66GswsLC9LtrrA3ND8/L91WPj9mZtlsfG9qbW1Nuv3JJ5+Es6dOnZJuHzlyJJxV970i+KYAAHCUAgDAUQoAAEcpAAAcpQAAcJQCAMBRCgAARykAABylAABwlAIAwIW3FPb29qTDA2GLIpFISbdTqX442+2qEw3xP41PJTPS7XQqfntnZ0e6vbu7K+W73V44u7QU/7N7M7NisRjObm1tSbfH4/h0xZGjZen2YKC9V3b34jMnE5VJ6fa7774bzp49e1a6rbw+iURCun3lypVwVpnyMDP79NNPpbwyn6NOUZy/8HI4O1HV3oelciGczea0OZwIvikAABylAABwlAIAwFEKAABHKQAAHKUAAHCUAgDAUQoAAEcpAAAcpQAAcJQCAMCFhzOazaZ0OJOJ7wIlEtrmTDIZ77JUSttVqtcb4Wy3E99gMjNbWFgIZzc3N6Xbly5dkvKvvHIxnL1+/bp0e2ZmJpz94IMPpNvvv/9+OPvgwbJ0+/D8opRfWloKZ0+cOCHdvnr16gt5HGZmc3Nz4Wwul5NuK5/71dVV6fbW9nMp32jEP8ujcXyrzczsN7/5TTh7+vRJ6bayGzceD6XbEXxTAAA4SgEA4CgFAICjFAAAjlIAADhKAQDgKAUAgKMUAACOUgAAOEoBAOAoBQCAC28fjbR5Iuv345scpVJJup3NZsPZei2+f2JmlknHt1uUDRkzs8nJyXD23Lnz0u1vf/vbUv7s2bPh7Pnz2mOZnZsPZ69c+SPp9ne/+044u7ysbR+t/Fbb4imVKuFstVqVbitbSernZ0p4H+bz8c+amVlByPd7Hel2p3Ug5UfD+DZZo96Vbt+5dVN4HNrtrc2dcDZh4i/mAL4pAAAcpQAAcJQCAMBRCgAARykAABylAABwlAIAwFEKAABHKQAAHKUAAHDhmQtlosHMbDAYhLPT09PS7XQ6/LCt2WhJt5X5h4sXL0q3t7e3w9mlpSXp9qVLl6T80aNHw1llVsTMrNmIT4uUK/GpCDOza6+9Fs5euHBBut3vxadZzMw2t+NzBNubW9JtSybC0Uwq/nkwM0skxuFsIZeXbiuzGOVSQbqtyufikzXdvja58cl//jKcvXvvc+l2MV8MZ/v9nnQ7gm8KAABHKQAAHKUAAHCUAgDAUQoAAEcpAAAcpQAAcJQCAMBRCgAARykAABylAABw4dGUqakp6fDJkyfD2W6nL92u1+vh7JUrV6TbyvZRtTop3d4WtnJqtZp0O5VKSfmpqZlwtlCMb7GYadtHnXZbut1qxbesRqORdLs6ob3H08I+UVHYBDIzUx55Qdj4MTPrdYXnfFSSbivvw+cbv5Nud9oHUt6G8f21frcrna7txj/LHXFXaaI0Eb/d1bbdIvimAABwlAIAwFEKAABHKQAAHKUAAHCUAgDAUQoAAEcpAAAcpQAAcJQCAMCFZy5yuZx0+Nq1a+HsypOn0m3lsbz99tvS7XK5HM4+fLgs3e504n/uXq1WpdvpdPilNDOzZrMZzqqvvfJzqvMpyuuTFR93Y29fyqeT8X9TTU5OSrfbwqRDv69NNCgzMYWs9hxOT0+Gs3fu3JJu79f2pHwiEZ8hae7XpNvlcnz6Zam6IN1WbGxoMzERfFMAADhKAQDgKAUAgKMUAACOUgAAOEoBAOAoBQCAoxQAAI5SAAA4SgEA4CgFAIALD+Zk0toGyu5OLZxNChsyZmaXL18OZ0+dOiXdrtVq4az6uJVNoPF4LN1Wdl7MzLrd+F7OwUF8h8fMbGc7vlGTSmak24PBIJzN5/vS7crEhJTPpuOPfTDoSbef7sf3iTotbf+m143nB+qukrBP9Gj5oXS7fRDf6zIzS6VS4WxD3j6Kb3Dlcy/uPV4q5qXbEXxTAAA4SgEA4CgFAICjFAAAjlIAADhKAQDgKAUAgKMUAACOUgAAOEoBAODCMxf5jDZzcfv27XD2+PET0u0LFy6Es72eNnWwv98IZ2dnZ6Xbyp+vr6+vS7fVKYqZmfhjH41G0m1lQkOVycQnAwqFgnR7PBiKjyb+vKizJcpzmM2FP8ZmZjaVmQpn1eew0Yh/ftT3bK8X//z8938RTjaa2u+Jbic+57FX25duK/Mc1WpVuh3BNwUAgKMUAACOUgAAOEoBAOAoBQCAoxQAAI5SAAA4SgEA4CgFAICjFAAAjlIAALjwaMryg0fS4U6vHc5evXJNum3D+I5MsyluAk3OhLONWnznxcxs2Itv63z++RfS7Vu37kj5Q4fmwtlOpyPdfrq6Er/dbUm3F5eWwtlEUtsbKor7XrlcfIcpk0pIt1d/+yScHSe121evXg1n1W2de3cfhLOraxvS7VY7vmVkZtZsNsPZgTbvZYV0fBMqlY2/T8zMFhcXw9nhUN3r+np8UwAAOEoBAOAoBQCAoxQAAI5SAAA4SgEA4CgFAICjFAAAjlIAADhKAQDgKAUAgAtvH21vb0uHyxOVcLZer0u3G434nlEmo+2OKPlUKiXdbrbjOz+jkTbG8v7770v5s2fPhrNvvfWWdHt1dfWFZM3MTtdq4exr17RNrZX1Z1J+bi6+HyXOMNmv790NZ1stbT/q8uXL4WwhX5JuP1h+GM4+fhzfyDIzaza1nzNfLIezpYr2WW63u+FsoxbfYDIzm6jGbx87dky6HcE3BQCAoxQAAI5SAAA4SgEA4CgFAICjFAAAjlIAADhKAQDgKAUAgKMUAAAuPHMxGA2lw5XJaji7tbsj3V7bWA9n1T8DL5Tjf9av/IxmZslkvIP7/b50+/6DB1L+yUp8YuDlc+ek2+8JkxvqnMfFixfD2Y31+PvEzOzaq1ek/IEwLzEQX8/nm5vh7MbGhnT7q+fPw9npmVnp9s5O/LOcz2el21u78fkHM7N2LZ4vFbU5j+Ew/vswndL+7d3cb4SznVZbuh3BNwUAgKMUAACOUgAAOEoBAOAoBQCAoxQAAI5SAAA4SgEA4CgFAICjFAAAjlIAALjw9tHUoRnp8MyhQ+Hsc2GLxczs0ZdfhrOHhMdhZrawuBjOTk9PS7cnqvGtpPv370u3U6mUlP/ss8/C2VdffVW6vbq6Gs6uCBtM6u3bt29Lt3/60hEpn83Gt3uyqfBHzczMPvnsVy/s9qeffhrOFgraJtCbb74Zzn61Fd93MjP71a/iz4mZ2Y2PPg5nx+OxdFvJl0rac1iv18PZJ0+eSLcj+KYAAHCUAgDAUQoAAEcpAAAcpQAAcJQCAMBRCgAARykAABylAABwlAIAwIX/Pr4yMSEdTmXif3q/tbUl3X62sR7O1oQ/GTczG45H4Wwqrc0LFErFcLbZakm3jx8/JuVv3YlPQLzz5+9Kt0+fPRPOPni4LN1eFiZOpoRZETOz+v6elO/1uuFso76vPZZGPF/IFaTbf/23fxPO/usHP5Vuf//73w9n1WmJo0ePvrD8xsaGdLsvvPbppPZv78R4GM6OBj3pdgTfFAAAjlIAADhKAQDgKAUAgKMUAACOUgAAOEoBAOAoBQCAoxQAAI5SAAA4SgEA4OLjPcmEdLjdbsfD4u3hML4N0jhoSrf39+ObM7VaTbo9GsV3ldQto+9973tS/ic/+Uk4e+fOHel2qVSS8oqMsKnV7mr7UTs7O1I+nU7Fb+9pu0rKLFA2G39fmZmtPlsLZxuNhnT7+vXr4ez9+/el25VKRcoXi/GtsXZH+H1lL/Zf07lcLpxNpeLvwSi+KQAAHKUAAHCUAgDAUQoAAEcpAAAcpQAAcJQCAMBRCgAARykAABylAABw4c2A3nAgHd6t18LZQqEg3R4Lsxir68+k27li/LHsbm1Lt7e2tsLZyclJ6fbly5el/IcffhjOfvHFF9LtqepkODszPSXd7vf74WxHnLmwhDi3MhbmJcR/fmXS8TmP0Sg++2JmlkrFH0y9EZ99MTO7e/9eOPvKK+el2+rviX6nG84+/nJZuq1M7aTT2otfzMdnYtTnJIJvCgAARykAABylAABwlAIAwFEKAABHKQAAHKUAAHCUAgDAUQoAAEcpAAAcpQAAcOGBFWVzxsys1Yrvzqj7HcrtlZUV6Xav1wtndzbjW0ZmZhsbG+FsNpuVbj969EjKKz9nqVCUbp88eTKcrVQq0u21tbVwdqJalm7nshkpX9uvh7MjbTrMCqV8OKt+NpXPW68Tf5+Yma2vxbfGzp19Wbqdz8efEzPtvTUYaC/QYBjfvUoKnzUzs1MnTsezp05JtyP4pgAAcJQCAMBRCgAARykAABylAABwlAIAwFEKAABHKQAAHKUAAHCUAgDAhWcu6vv70uFcLhfO1mo16fbBwUE4q84odDqd+OPYb0i3M5n4jELSEtLtibL2c6YS8X8P3Lt7V7r9p9/6Vjh7eG5Our36dDWcnZ6ckm5XKuIsRi7+eo768YkTM7N2qxnOJiwl3R4Ir/2pE8el28N+fNKh1Yj/jGZmubQ2Q/LqlUvh7D//03vS7V43PouhTMqYmd2/H/+8bW5+Jd2O4JsCAMBRCgAARykAABylAABwlAIAwFEKAABHKQAAHKUAAHCUAgDAUQoAAEcpAABcePsonQ5HzcwskYhv96jbIMr2UaOh7RMVc/lwdjweS7fHw1E4my8XpdurT59K+emp+C5QbWdXun3381+Hs4empqXbczMz4Wy/05Vuj4sFKZ8W9qnU3Z60sE+UFLePSsVSODs7c0i6PTs7G86WS/HHYWZ24fx5KX/z5s1wVv39tleL/17JpLTXJyXkNzc3pdsRfFMAADhKAQDgKAUAgKMUAACOUgAAOEoBAOAoBQCAoxQAAI5SAAA4SgEA4CgFAIALD37EV15+L5WM9814pG0IdXr9cLbdi+8kmZl1M+1wNpfJSreV51B5/szMKsKejZnZ0vxCOPsfN29LtxcOz4ez586dk24vP3gYzjb3a9LtA22ixjKp+GuUT2rbOiPh32vdvrYd1m3HPxOdg5Z2uxT//KyurEi3v/GN16X848ePw9lCQdu9Khbiz+GMsNdlZpYUPvvr6+vS7dD//3/9IgDgDxalAABwlAIAwFEKAABHKQAAHKUAAHCUAgDAUQoAAEcpAAAcpQAAcOG/vT840OYiRqNROJtLZ6TbmUw8Px5rExomTG70ul3pdEK4vT+MP39mZpmUNqPwzde/Ec7++799IN3+3bP4n96fPn5Cuq3kP/zoF9LthDgXUZ2shLOVfFG6nU7HX0/1s9kRfs52U7tdz9TC2UqpLN1WH0uv3Yk/lkr8tTQzK5XiszKLi4vS7Vwu98JuR/BNAQDgKAUAgKMUAACOUgAAOEoBAOAoBQCAoxQAAI5SAAA4SgEA4CgFAICjFAAALjywouyImGk7PyNx+0giPA4zs7Gw2dQfDKTbw/4wnG2Lz/cvb92W8j/+8Y/D2XffeUe6/d5774Wztz6+Kd3+4Q9/GM7ubj6Xbg86LSk/Mz0ZzmazWel2UdjW6QvvKzOzdi++2XX48GHptvK4h5aQbj96uCzl+8LG0972tnQ7L/yc2+LtQjG+k1UUslF8UwAAOEoBAOAoBQCAoxQAAI5SAAA4SgEA4CgFAICjFAAAjlIAADhKAQDgEuPxOLQDUapof049EuYixsN41sws+JDNzCyZ0P6UPp2I92RCvJ0QFjeOLCxKtzfW16X8mTNnwtlcRptoqFar4ex0dVK6/YMf/CCc/Zf3/lG6ffvGL6R8PhufZ+kN+tLtQqEQzo6E96yZ2WAYn8U4NDcr3c4W8uHs1vaudLtQjk9LmJntNxrh7Bf37kq3M/n4z9loNqXbwstjFfH38u7+wddm+KYAAHCUAgDAUQoAAEcpAAAcpQAAcJQCAMBRCgAARykAABylAABwlAIAwFEKAACXjgaz6fjOi5lZvx/fehmMhbEPMzNh+ygl7sJks/Gdn1JB2x0pZHPhrLqrdOLECSm/u70Tzh6ampZuWzm+ZfXk8WPp9M2PPw5n/+w735Fub68/k/KDTjuc3drZlm6nLf76J5LaezyTFN5bI2Gwy8w6B61wdm3tqXQ7V4zvQZmZ5fLxz2elUpFu94VtNyFqZmbKM15rxJ/vKL4pAAAcpQAAcJQCAMBRCgAARykAABylAABwlAIAwFEKAABHKQAAHKUAAHDhmYtOpyMdHil/2y3MVqjUuYh0OvyUWCmv/dm98qf0C/Pz0m3lcZuZ7T7fCmfnxceysb4eztZqNen2Rx/+PJwdtuMzFGZmmWRKyvcG8XmWXqcr3R5l45+ffD6v3R7Hb3fE57DdE35O8XMv/U4xs+3t+LSI9LjNrL4fn5dQf7tNTk+Es81mU7z+9fimAABwlAIAwFEKAABHKQAAHKUAAHCUAgDAUQoAAEcpAAAcpQAAcJQCAMBRCgAAlxiPX+DwEADgDwrfFAAAjlIAADhKAQDgKAUAgKMUAACOUgAAOEoBAOAoBQCAoxQAAO6/AI23ADs/SSoGAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "После загрузки изображения в переменную мы должны преобразовать его в массив numpy. Здесь изображение преобразуется в массив, а затем расширяется в соответствии с размерами массива согласно строке. (Для преобразования используется img_to_array)"
      ],
      "metadata": {
        "id": "7-QZYt9Qqevn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import img_to_array\n",
        "imgtest=img_to_array(img)\n",
        "list_of_image=np.expand_dims(imgtest,axis=0)"
      ],
      "metadata": {
        "id": "6wWI6INpqkC-"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "После преобразования в массив. Затем на основе массива делаются прогнозы."
      ],
      "metadata": {
        "id": "hFipy26Uqr5_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "res=model.predict(list_of_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8P9VoYKnqvz2",
        "outputId": "19559265-ae6c-4df4-9ee6-ef4d31845ab2"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Учитывается только один результат, так как берется только одно изображение. Если есть группа изображений, то запускается цикл, или набор данных классифицируется соответствующим образом. Распечатывается массив для всех меток."
      ],
      "metadata": {
        "id": "g5VHtCZ0q7vP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sr=res[0]\n",
        "print(sr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dPZu6RpOq8dG",
        "outputId": "a54f5bf2-58ac-4711-d69d-4fff2f71883b"
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0. 0. 0. 0. 0. 0. 0. 1. 0. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы получим оценку, которая представляет собой вероятность всех 10 возможных классов. Когда изображение получает наивысшую оценку вероятности, ему присваивается метка. В результате будет выведена метка изображения."
      ],
      "metadata": {
        "id": "JOOMoeJkrEa3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mostlci=int(np.argmax(sr))\n",
        "clh=class_labels[mostlci]\n",
        "print(clh,mostlci)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tnAokHisrI1t",
        "outputId": "6da9d858-ac8e-4260-d5b0-cf3ec927ca34"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Horse 7\n"
          ]
        }
      ]
    }
  ]
}